# Alternative Splicing Pipeline (Nextflow)

Nextflow DSL2 scaffold for alternative splicing analyses on genome-aligned paired-end RNA-seq BAMs. The workflow is organized for junction discovery, event-level calls, isoform assembly/quantification, and reporting.

## Layout
- `main.nf` – pipeline entry with stubbed processes for junction extraction (regtools), event callers (rMATS/LeafCutter), assembly/quantification (StringTie/gffcompare/Salmon), and plotting hooks.
- `nextflow.config` – defaults for params, executors, and log/output locations; extend with per-environment profiles under `conf/`.
- `metadata/` – sample sheet lives here (see `metadata/samples.tsv` template).
- `resources/` – reference genome/annotation (FASTA/GTF) and any tool-specific indexes.
- `modules/local/`, `bin/` – place custom Nextflow modules and helper scripts.
- `results/`, `logs/` – pipeline outputs; `work/` is created by Nextflow at runtime.

## Metadata (uses your provided table)
`metadata/samples.tsv` is the real dataset you supplied (columns: `Run`, `Experiment`, `BiologicalState`, `Stranded`, `ReadLength`, `Use`, ...). The pipeline auto-derives:
- `sample_id` ← `Run`
- `condition` ← `BiologicalState`
- `strandedness` ← `Stranded` (expects `RF` or `FR`; falls back to `params.strandedness`)
- `readlen` ← `ReadLength` (used to pick/build STAR indices)
- only rows with `Use=TRUE` / `YES` / `1` are processed

To limit the run to a subset (e.g., 2 conditions × 3 replicates), set `Use=TRUE` for those rows and `FALSE` for the rest.
FASTQ paths are loaded from `metadata/samplesheet.csv`, which is generated by `nf-core/fetchngs` (see below).

## Fetch FASTQs (once)
You can create `ids.csv` from the `Experiment` values from `metadata/samples.tsv` and download FASTQs with:

```bash
cut -f14 alternative_splicing/metadata/samples.tsv | tail -n +2 > ids.csv
export SRA_DATA=/home/lab/kim/hd/rnaseq/reads_pe/raw/
nextflow run nf-core/fetchngs --input ./ids.csv --outdir ${SRA_DATA}
```

Point `params.samplesheet` in `nextflow.config` to the resulting `${SRA_DATA}/samplesheet/samplesheet.csv`. It should contain columns like these:
```
sample	fastq_1	fastq_2	run_accession	experiment_accession	sample_accession ...
```


## Running
Update `gtf` and `fasta` (reference) in `nextflow.config` or via `-params-file` and launch:

```bash
cd alternative_splicing
nextflow run main.nf -profile local \
  --samples metadata/samples.tsv \
  --gtf resources/reference.gtf \
  --fasta resources/reference.fasta \
  --outdir results
```

Outputs land under `results/` and `logs/`. Swap `-profile` once you add HPC/cloud settings under `conf/`.

## What the pipeline does now (StringTie.sh parity)
- Downloads SRA runs (from the `Run` column) with `fasterq-dump` → gzip
- QC/trim with `fastp`
- Builds STAR indices per read length automatically under `resources/star_index/`
- Aligns with STAR → sorted BAM + index
- Assembles with StringTie
- Downstream placeholders: regtools junctions, gffcompare merge/compare, LeafCutter/rMATS prep, transcriptome build, Salmon quant

## Requirements
- SRA Toolkit (`prefetch`/`fasterq-dump`), `fastp`, `STAR`, `samtools`, `stringtie`
- Reference FASTA/GTF set via `--fasta` / `--gtf`
